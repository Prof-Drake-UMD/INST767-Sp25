# ğŸ” Job Market Data Integration Pipeline  
*A multi-source ETL project for job search using Google Cloud Platform*



## ğŸ“˜ Project Overview

<!-- This project is part of the final assignment for INST767 (Sp25), focusing on building a **cloud-native data pipeline** using **Google Cloud Platform** tools. The goal is to **extract**, **transform**, and **load** data from multiple external APIs into **BigQuery**, enabling further analysis and unified access via a single API. -->

As a person pursuing a Master's in HCI with a background in computer science, this project aims to provide people with similar background to have a simplified job search experience. This is a ETL pipeline that integrates data from three different job market APIsâ€”tailored for entry level general, tech, and design roles. 



<!-- ## ğŸ§­ Objective

Build an automated data pipeline using **Apache Airflow** (via **Cloud Composer**) that:

- Pulls data from **three external job-related APIs**
- Transforms the data into a **unified schema**
- Loads the cleaned data into **BigQuery** -->


## ğŸ”— Data Sources

| API | Focus | Update Frequency | Docs |
|-----|-------|------------------|------|
| **The Muse** | Creative & Design Jobs | Daily | [API Docs](https://www.themuse.com/developers/api/v2) |
| **Adzuna** | Technical / Engineering Roles | Every 6 hours | [API Docs](https://developer.adzuna.com/) |
| **Jooble** | Broad job listings (Entry level / Hourly Jobs) | Daily | [API Docs](https://jooble.org/api/about) |




<!-- ## ğŸ—ï¸ Architecture

The system follows a ETL pattern using Google Cloud services:

```
[ Muse / Adzuna / Jooble APIs ] 
        â†“
[ Python API Connectors ]
        â†“
[ Cloud Composer (Airflow DAG) ]
        â†“
[ GCS (intermediate storage) ]
        â†“
[ BigQuery (final storage & analysis) ]
``` -->



## ğŸ§± Components

### ğŸ› ï¸ Extraction (Beginning of Ingest)
- Custom Python modules (`muse_api.py`, etc.)
- Retry logic and error handling
- Pulls raw data from APIs and writes to json files

<!-- ### ğŸ§¼ Transformation
- Converts inconsistent fields into a **standardized schema**
- Cleans nulls, infers job types, standardizes skills and salary -->

<!-- ### ğŸ§© Unified Schema

```json
{
  "job_id": "string",
  "category": "string", 
  "title": "string",
  "company": "string",
  "location": "string",
  "description": "string",
  "salary_info": "string | null",
  "employment_type": "string",
  "posted_date": "date",
  "skills_required": ["string"],
  "experience_level": "string | null",
  "source_api": "string",
  "additional_metadata": "object | null"
}
``` -->

<!-- ### ğŸ“¥ Loading
- Transformed files written to GCS in newline-delimited JSON
- Loaded into partitioned BigQuery table by `posted_date` -->

### ğŸ“… Update Schedule

| Source | Schedule |
|--------|----------|
| The Muse | Daily at 12:00 UTC |
| Adzuna | Every 6 hours |
| Jooble | Daily at 06:00 UTC |



<!-- ## ğŸ“ File Structure

```
firstname_lastname/
â”œâ”€â”€ README.md
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ job_data_pipeline.py
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ muse_connector.py
â”‚       â”œâ”€â”€ adzuna_connector.py
â”‚       â”œâ”€â”€ jooble_connector.py
â”‚       â””â”€â”€ data_transformer.py
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ unified_job_schema.json
â””â”€â”€ sql/
    â””â”€â”€ analysis_queries.sql
``` -->



<!-- ## ğŸŒ API Layer 

The cleaned job data in BigQuery is exposed via a basic RESTful API. -->

<!-- ### Base URL

```
https://your-api-url.com/jobs
```

### GET /jobs â€” Query Parameters

| Parameter | Type | Example | Description |
|----------|------|---------|-------------|
| `location` | string | `Remote` | Filter by location |
| `role` | string | `Engineer` | Job title keyword |
| `employment_type` | string | `freelance` | Filter job type |
| `source_api` | string | `adzuna` | Filter by source |
| `skills` | string[] | `["Python"]` | Filter by skills |

### Example Response

```json
[
  {
    "job_id": "adz-87493",
    "title": "Backend Engineer",
    "company": "Techie Inc.",
    "location": "Remote",
    "salary_info": "$100kâ€“$120k",
    "employment_type": "full-time",
    "posted_date": "2025-03-29",
    "skills_required": ["Python", "Django", "SQL"],
    "source_api": "adzuna"
  }
]
``` -->



<!-- ## ğŸ“Š Analytical Use Cases

With the integrated dataset in BigQuery, we can explore:

- Job **trends by location** or **job type**
- **Salary** insights for similar roles across platforms
- **Skill demand** across different industries
- Comparison: **Freelance vs Full-time** opportunities



## ğŸ”® Future Enhancements

- âœ… Add **data validation and anomaly detection**
- ğŸ§  Perform **sentiment analysis** on job descriptions
- ğŸ“ˆ Build a **dashboard** in Looker Studio for recruiters
- ğŸŒ Add more regional or international job boards
- ğŸ›¡ï¸ Implement **OAuth or API key protection** -->



<!-- ## ğŸ§‘â€ğŸ’» Technologies Used

- **Google Cloud Platform**
  - Cloud Composer (Airflow)
  - Cloud Storage
  - BigQuery
- **Python**
  - `requests`, `pandas`, `datetime`
- **APIs**
  - The Muse, Adzuna, Jooble -->
<!-- - FastAPI or Flask for REST API Layer -->


